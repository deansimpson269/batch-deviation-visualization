{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f69c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in ./opt/miniconda3/lib/python3.9/site-packages (2.0.1)\n",
      "    Batch ID Batch Date  Deviation Occurred      Deviation Type  Severity  \\\n",
      "0  BMSD-0001 2024-09-26                True    Filtration Issue     Major   \n",
      "1  BMSD-0002 2024-08-30                True  Particulate Matter     Major   \n",
      "2  BMSD-0003 2024-04-28                True   Sterility Failure     Major   \n",
      "3  BMSD-0004 2024-06-30                True  Particulate Matter  Critical   \n",
      "6  BMSD-0007 2024-07-27                True        pH Deviation     Minor   \n",
      "\n",
      "                  Impact  \n",
      "0        Delayed Release  \n",
      "1  Reprocessing Required  \n",
      "2  Reprocessing Required  \n",
      "3  Reprocessing Required  \n",
      "6  Reprocessing Required  \n"
     ]
    }
   ],
   "source": [
    "# Install the xlrd library (only needed for reading .xls Excel files)\n",
    "!pip install xlrd\n",
    "\n",
    "# Import the pandas library for data handling\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the excel file\n",
    "file_path = 'Synthetic_Batch_Data.xls'\n",
    "\n",
    "# Load the excel file into a DataFrame using the xlrd engine\n",
    "#(xlrd is required for legacy .xls formats, not for xlsx)\n",
    "#Specify engine as 'xlrd' because it's a .xls (older Excel format)\n",
    "exceldoc = pd.read_excel(file_path, engine = 'xlrd')\n",
    "\n",
    "# Remove rows where all columns have missing values (NaNs)\n",
    "exceldoc = exceldoc.dropna()\n",
    "\n",
    "# Replace any remaining NaNs with the string 'None'\n",
    "exceldoc = exceldoc.fillna(value = 'None')\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(exceldoc.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c688aba",
   "metadata": {},
   "source": [
    "# Chunk 1: Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fedf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: View structure and dimentions of the dataset\n",
    "print(exceldoc.info()) # column names, data types, and non-null counts\n",
    "print(exceldoc.shape)  # (rows, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2d9c8",
   "metadata": {},
   "source": [
    "# Chunk 2: Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df530697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many missing values exist in each column\n",
    "print(exceldoc.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b77b76",
   "metadata": {},
   "source": [
    "# Chunk 3: Dropping rows missing Severity or Impact info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551926ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows that are missing values in the 'Severity' or 'Impact' columns\n",
    "# This ensures all records used in analysis contain key quality metrics\n",
    "clean_excel = exceldoc.dropna(subset = ['Severity', 'Impact'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3d16ac",
   "metadata": {},
   "source": [
    "# Chunk 4: Confirming new shape after cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm new shape after dropping incomplete rows\n",
    "print(exceldoc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7447f",
   "metadata": {},
   "source": [
    "# Chunk 5: Count unique values for two key columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d423c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count how many times each Severity level appears\n",
    "print(exceldoc['Severity'].value_counts())\n",
    "\n",
    "#Count how many times each Impact level appears\n",
    "print(exceldoc['Impact'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915aac8",
   "metadata": {},
   "source": [
    "# Chunk 6: Clean text column for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the values in the 'Deviation Type' column by:\n",
    "# - Removing extra spaces\n",
    "# - Converting all text to lowercase\n",
    "# This ensures that entries like \"Operator Error\" and \"operator error\" are treated as the same category. \n",
    "exceldoc['Deviation Type'] = exceldoc['Deviation Type'].str.strip().str.lower()\n",
    "\n",
    "#Count how many times each unique Deviation Type appears after standardization\n",
    "deviation_counts = exceldoc['Deviation Type'].value_counts()\n",
    "print(deviation_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219edb8c",
   "metadata": {},
   "source": [
    "# Chunk 7: Visualize top deviation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create a horizontal bar chart to show the most common deviation types\n",
    "plt.figure(figsize = (10,6))\n",
    "deviation_counts.plot(kind = 'barh', color = 'skyblue')\n",
    "\n",
    "#Add titles and labels for clarity\n",
    "plt.title('Top Deviation Types')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Deviation Type')\n",
    "\n",
    "#Flip the y-axis to show the most frequent deviation at the top\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc2e3b",
   "metadata": {},
   "source": [
    "# Chunk 8: Visualize severity breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of deviations per severity level\n",
    "severity_counts = exceldoc['Severity'].value_counts()\n",
    "\n",
    "#Plot a horizontal bar chart of severity distribution\n",
    "plt.figure(figsize = (8,5))\n",
    "severity_counts.plot(kind = 'barh', color = 'red')\n",
    "plt.title('Deviation Severity Distribution')\n",
    "plt.xlabel('Severity')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dfccca",
   "metadata": {},
   "source": [
    "# Chunk 9: Visualize impact breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b726764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of deviations per impact level\n",
    "impact_counts = exceldoc['Impact'].value_counts()\n",
    "\n",
    "#Plot a horizontal bar chart of impact distribution\n",
    "plt.figure(figsize = (8,5))\n",
    "impact_counts.plot(kind = 'barh', color = 'green')\n",
    "plt.title('Deviation Impact Distribution')\n",
    "plt.xlabel('Impact')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation = 45)\n",
    "plt.gca\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae96ce",
   "metadata": {},
   "source": [
    "# Chunk 10: Create a severity vs. impact correlation table and heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a cross tabulation between Severity and Impact\n",
    "cross_tab = pd.crosstab(exceldoc['Severity'], exceldoc['Impact'])\n",
    "print(cross_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684034a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the cross-tab as a heatmap using seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "#Generate annotated heatmap with custom color palette\n",
    "sns.heatmap(cross_tab, annot = True, fmt = 'd', cmap = 'YlOrRd')\n",
    "plt.title('Severity vs. Impact Heatmap')\n",
    "plt.xlabel('Impact')\n",
    "plt.ylabel('Severity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc79b11b",
   "metadata": {},
   "source": [
    "# **NLP-Powered Batch Deviation Analysis**\n",
    "\n",
    "## **Overview**\n",
    "This project analyzes synthetic batch deviation data from a GMP manufacturing process using Python for data cleaning, NLP-based text normalization, and exploratory data analysis (EDA).\n",
    "\n",
    "The goal is to extract meaningul insights from deviation logs - helping quality and compliance teams understand trends in severity, impact, and root cause. \n",
    "\n",
    "---\n",
    "\n",
    "## **Key Visuals**\n",
    "- **Top deviation types ** (bar chart)\n",
    "- **Severity breakdown** (red bar chart)\n",
    "- **Impact breakdown** (green bar chart)\n",
    "- **Heatmap: Severity vs. Impact** (annotated heat map)\n",
    "\n",
    "---\n",
    "\n",
    "## **Insights**\n",
    "- **Major deviations** are most often associated with **reprocessing required**.\n",
    "- **Critical deviations** frequenty result in *scrapping batches* or *delayed release*.\n",
    "- A small subset of deviation types accounts for most batch issues, suggesting high-leverage opportunities for SOP improvement or equipment calibration.\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Notes**\n",
    "This notebook demonstrates:\n",
    "- Data import and cleaning using 'pandas'.\n",
    "- Text normalization using Python string methods.\n",
    "- Data Visualization with 'matplotlib' and 'seaborn'.\n",
    "- Exploratory insights relevant to quality control and GMP compliance.\n",
    "\n",
    "\n",
    "> All code was written and executed in a local Jupyter Notebook environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb528d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
